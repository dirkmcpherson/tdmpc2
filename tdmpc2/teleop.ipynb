{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from hydra import initialize, initialize_config_dir, initialize_config_module, compose\n",
    "from omegaconf import OmegaConf\n",
    "from common.parser import parse_cfg\n",
    "from common import MODEL_SIZE, TASK_SET\n",
    "import re\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "from common.buffer import ReplayBuffer\n",
    "\n",
    "with initialize(version_base=None, config_path='.'):\n",
    "    cfg = compose(config_name='config.yaml')\n",
    "\n",
    "    # Logic\n",
    "    for k in cfg.keys():\n",
    "        try:\n",
    "            v = cfg[k]\n",
    "            if v == None:\n",
    "                v = True\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Algebraic expressions\n",
    "    for k in cfg.keys():\n",
    "        try:\n",
    "            v = cfg[k]\n",
    "            if isinstance(v, str):\n",
    "                match = re.match(r\"(\\d+)([+\\-*/])(\\d+)\", v)\n",
    "                if match:\n",
    "                    cfg[k] = eval(match.group(1) + match.group(2) + match.group(3))\n",
    "                    if isinstance(cfg[k], float) and cfg[k].is_integer():\n",
    "                        cfg[k] = int(cfg[k])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    cfg.buffer_size = 50000\n",
    "    # Convenience\n",
    "    cfg.work_dir = '.'\n",
    "    cfg.task_title = cfg.task.replace(\"-\", \" \").title()\n",
    "    cfg.bin_size = (cfg.vmax - cfg.vmin) / (cfg.num_bins-1) # Bin size for discrete regression\n",
    "\n",
    "    # Model size\n",
    "    if cfg.get('model_size', None) is not None:\n",
    "        assert cfg.model_size in MODEL_SIZE.keys(), \\\n",
    "            f'Invalid model size {cfg.model_size}. Must be one of {list(MODEL_SIZE.keys())}'\n",
    "        for k, v in MODEL_SIZE[cfg.model_size].items():\n",
    "            cfg[k] = v\n",
    "        if cfg.task == 'mt30' and cfg.model_size == 19:\n",
    "            cfg.latent_dim = 512 # This checkpoint is slightly smaller\n",
    "\n",
    "    # Multi-task\n",
    "    cfg.multitask = cfg.task in TASK_SET.keys()\n",
    "    if cfg.multitask:\n",
    "        cfg.task_title = cfg.task.upper()\n",
    "        # Account for slight inconsistency in task_dim for the mt30 experiments\n",
    "        cfg.task_dim = 96 if cfg.task == 'mt80' or cfg.model_size in {1, 317} else 64\n",
    "    else:\n",
    "        cfg.task_dim = 0\n",
    "    cfg.tasks = TASK_SET.get(cfg.task, [cfg.task])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pusht force sparse reward:  False\n"
     ]
    }
   ],
   "source": [
    "from envs import make_env\n",
    "env = make_env(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pynput import mouse\n",
    "import time\n",
    "\n",
    "from tensordict.tensordict import TensorDict\n",
    "def to_td(obs, env, action=None, reward=None):\n",
    "    \"\"\"Creates a TensorDict for a new episode.\"\"\"\n",
    "    if isinstance(obs, dict):\n",
    "        obs = TensorDict(obs, batch_size=(), device='cpu')\n",
    "    else:\n",
    "        obs = obs.unsqueeze(0).cpu()\n",
    "    if action is None:\n",
    "        action = torch.full_like(env.rand_act(), float('nan'))\n",
    "    if reward is None:\n",
    "        reward = torch.tensor(float('nan'))\n",
    "    td = TensorDict(dict(\n",
    "        obs=obs,\n",
    "        action=action.unsqueeze(0),\n",
    "        reward=reward.unsqueeze(0),\n",
    "    ), batch_size=(1,))\n",
    "    return td\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "27\n",
      "Buffer capacity: 50,000\n",
      "Storage required: 1.84 GB\n",
      "Using CUDA memory for storage.\n"
     ]
    }
   ],
   "source": [
    "from common.buffer import Buffer\n",
    "buffer = Buffer(cfg)\n",
    "\n",
    "global next_action\n",
    "next_action = np.array([0,0])\n",
    "\n",
    "minx, maxx = 500, 1500\n",
    "miny, maxy = 300, 700\n",
    "def on_move(x, y):\n",
    "    if x < minx or x > maxx or y < miny or y > maxy: return np.array([0, 0])\n",
    "    \n",
    "    xnorm = (x - minx) / (maxx - minx)\n",
    "    ynorm = (y - miny) / (maxy - miny)\n",
    "\n",
    "    xnorm = max(0, min(1, xnorm))\n",
    "    ynorm = max(0, min(1, ynorm))\n",
    "\n",
    "    xnorm = 2 * xnorm - 1\n",
    "    ynorm = 2 * ynorm - 1\n",
    "\n",
    "    # print(f'Pointer moved to {(x, y)} -> {xnorm, ynorm}')\n",
    "    global next_action\n",
    "    next_action = np.array([xnorm, ynorm])\n",
    "\n",
    "# Create a listener\n",
    "listener = mouse.Listener(on_move=on_move)\n",
    "\n",
    "# Start the listener\n",
    "listener.start()\n",
    "cv2.destroyAllWindows()\n",
    "obs, done, ep_reward, t = env.reset(), False, 0, 0\n",
    "tds = [to_td(obs, env)]\n",
    "eps = 0; ts = 0\n",
    "while eps < 20:\n",
    "    # action = torch.Tensor(env.action_space.sample())\n",
    "    action = torch.Tensor(next_action)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    tds.append(to_td(obs, env, action, reward))\n",
    "\n",
    "    if done or ts >= 300:\n",
    "        eps += 1; ts = 0\n",
    "        buffer.add(torch.cat(tds))\n",
    "        obs, done, ep_reward, t = env.reset(), False, 0, 0\n",
    "        tds = [to_td(obs, env)]\n",
    "\n",
    "\n",
    "    img = obs.detach().cpu().numpy()\n",
    "    # Step 1: Reshape the stack into separate images\n",
    "    img = img.transpose(1, 2, 0)\n",
    "    # reshaped = np.hstack([img[:,:,i*3:(i*3)+3] for i in range(3)])\n",
    "    reshaped = img[:, :, -3:]\n",
    "    reshaped = cv2.resize(reshaped, (reshaped.shape[1] * 3, reshaped.shape[0] * 3), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Step 3: Display using OpenCV\n",
    "    cv2.imshow('row', reshaped)\n",
    "    k = cv2.waitKey(100) & 0xFF\n",
    "    print(k)\n",
    "    if k == 27: \n",
    "        buffer.add(torch.cat(tds))\n",
    "        break\n",
    "\n",
    "    ts += 1\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "listener.stop()\n",
    "import os\n",
    "\n",
    "path = os.path.expanduser(\"~/workspace/tdmpc2/demonstrations/HD_1\")\n",
    "buffer.save(path)\n",
    "\n",
    "num_eps = buffer._num_eps; cap = buffer.capacity\n",
    "rb_load = Buffer(cfg); rb_load.load(path)\n",
    "rb_load._num_eps = num_eps; rb_load._capacity = cap\n",
    "\n",
    "print(f\"{rb_load._num_eps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [0] at index 0 does not match the shape of the indexed tensor [1, 1] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m s1 \u001b[38;5;241m=\u001b[39m \u001b[43mbuffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(s1)\n\u001b[1;32m      5\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/workspace/tdmpc2/tdmpc2/common/buffer.py:96\u001b[0m, in \u001b[0;36mBuffer.sample\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     95\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sample a batch of subsequences from the buffer.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m     td \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mhorizon\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_batch(td)\n",
      "File \u001b[0;32m~/workspace/tdmpc2/venv/lib/python3.9/site-packages/torchrl/data/replay_buffers/replay_buffers.py:606\u001b[0m, in \u001b[0;36mReplayBuffer.sample\u001b[0;34m(self, batch_size, return_info)\u001b[0m\n\u001b[1;32m    604\u001b[0m             fut \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prefetch_executor\u001b[38;5;241m.\u001b[39msubmit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample, batch_size)\n\u001b[1;32m    605\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prefetch_queue\u001b[38;5;241m.\u001b[39mappend(fut)\n\u001b[0;32m--> 606\u001b[0m         ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prefetch_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopleft\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_info:\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m/usr/lib/python3.9/concurrent/futures/_base.py:446\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/usr/lib/python3.9/concurrent/futures/_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    394\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.9/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/workspace/tdmpc2/venv/lib/python3.9/site-packages/torchrl/data/replay_buffers/utils.py:50\u001b[0m, in \u001b[0;36mpin_memory_output.<locals>.decorated_fun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorated_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 50\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m     52\u001b[0m         _tuple_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/tdmpc2/venv/lib/python3.9/site-packages/torchrl/data/replay_buffers/replay_buffers.py:540\u001b[0m, in \u001b[0;36mReplayBuffer._sample\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;129m@pin_memory_output\u001b[39m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sample\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch_size: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, \u001b[38;5;28mdict\u001b[39m]:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replay_lock:\n\u001b[0;32m--> 540\u001b[0m         index, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_storage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    541\u001b[0m         info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m index\n\u001b[1;32m    542\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage\u001b[38;5;241m.\u001b[39mget(index)\n",
      "File \u001b[0;32m~/workspace/tdmpc2/venv/lib/python3.9/site-packages/torchrl/data/replay_buffers/samplers.py:1020\u001b[0m, in \u001b[0;36mSliceSampler.sample\u001b[0;34m(self, storage, batch_size)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\u001b[38;5;28mself\u001b[39m, storage: Storage, batch_size: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;28mdict\u001b[39m]:\n\u001b[1;32m   1019\u001b[0m     \u001b[38;5;66;03m# pick up as many trajs as we need\u001b[39;00m\n\u001b[0;32m-> 1020\u001b[0m     start_idx, stop_idx, lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_stop_and_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m     \u001b[38;5;66;03m# we have to make sure that the number of dims of the storage\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;66;03m# is the same as the stop/start signals since we will\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;66;03m# use these to sample the storage\u001b[39;00m\n\u001b[1;32m   1024\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m start_idx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m storage\u001b[38;5;241m.\u001b[39mndim:\n",
      "File \u001b[0;32m~/workspace/tdmpc2/venv/lib/python3.9/site-packages/torchrl/data/replay_buffers/samplers.py:965\u001b[0m, in \u001b[0;36mSliceSampler._get_stop_and_length\u001b[0;34m(self, storage, fallback)\u001b[0m\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    962\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    963\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not get a tensordict out of the storage, which is required for SliceSampler to compute the trajectories.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    964\u001b[0m         )\n\u001b[0;32m--> 965\u001b[0m vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_find_start_stop_traj\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrajectory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrajectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mat_capacity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_is_full\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_values:\n\u001b[1;32m    969\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop-and-length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m vals\n",
      "File \u001b[0;32m~/workspace/tdmpc2/venv/lib/python3.9/site-packages/torchrl/data/replay_buffers/samplers.py:886\u001b[0m, in \u001b[0;36mSliceSampler._find_start_stop_traj\u001b[0;34m(cls, trajectory, end, at_capacity)\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    883\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    884\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected the end-of-trajectory signal to be at least 1-dimensional.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    885\u001b[0m     )\n\u001b[0;32m--> 886\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_end_to_start_stop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/tdmpc2/venv/lib/python3.9/site-packages/torchrl/data/replay_buffers/samplers.py:907\u001b[0m, in \u001b[0;36mSliceSampler._end_to_start_stop\u001b[0;34m(end, length)\u001b[0m\n\u001b[1;32m    905\u001b[0m m2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([start_idx_mask, torch\u001b[38;5;241m.\u001b[39mzeros_like(start_idx_mask[:\u001b[38;5;241m1\u001b[39m])])\n\u001b[1;32m    906\u001b[0m start_idx_replace \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mempty_like(start_idx)\n\u001b[0;32m--> 907\u001b[0m start_idx_replace[m1] \u001b[38;5;241m=\u001b[39m \u001b[43mstart_idx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mm2\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    908\u001b[0m start_idx_replace[\u001b[38;5;241m~\u001b[39mm1] \u001b[38;5;241m=\u001b[39m start_idx[\u001b[38;5;241m~\u001b[39mm2]\n\u001b[1;32m    909\u001b[0m start_idx \u001b[38;5;241m=\u001b[39m start_idx_replace\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [0] at index 0 does not match the shape of the indexed tensor [1, 1] at index 0"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "s1 = buffer.sample()\n",
    "print(s1)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "s2 = rb_load.sample()\n",
    "print(s1)\n",
    "print(len(rb_load._buffer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_load._buffer[0][\"obs\"].shape, rb_load._buffer[0][\"action\"], rb_load._buffer[0][\"reward\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = img.reshape(64, 64, 3, 3)\n",
    "a = img\n",
    "cv2.imshow('a', a)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
