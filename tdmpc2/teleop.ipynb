{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j/workspace/tdmpc2/venv/lib/python3.9/site-packages/torchrl/data/replay_buffers/samplers.py:37: UserWarning: Failed to import torchrl C++ binaries. Some modules (eg, prioritized replay buffers) may not work with your installation. If you installed TorchRL from PyPI, please report the bug on TorchRL github. If you installed TorchRL locally and/or in development mode, check that you have all the required compiling packages.\n",
      "  warnings.warn(EXTENSION_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from hydra import initialize, initialize_config_dir, initialize_config_module, compose\n",
    "from omegaconf import OmegaConf\n",
    "from common.parser import parse_cfg\n",
    "from common import MODEL_SIZE, TASK_SET\n",
    "import re\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from common.buffer import Buffer, ReplayBuffer\n",
    "\n",
    "with initialize(version_base=None, config_path='.'):\n",
    "    cfg = compose(config_name='config.yaml')\n",
    "\n",
    "    # Logic\n",
    "    for k in cfg.keys():\n",
    "        try:\n",
    "            v = cfg[k]\n",
    "            if v == None:\n",
    "                v = True\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Algebraic expressions\n",
    "    for k in cfg.keys():\n",
    "        try:\n",
    "            v = cfg[k]\n",
    "            if isinstance(v, str):\n",
    "                match = re.match(r\"(\\d+)([+\\-*/])(\\d+)\", v)\n",
    "                if match:\n",
    "                    cfg[k] = eval(match.group(1) + match.group(2) + match.group(3))\n",
    "                    if isinstance(cfg[k], float) and cfg[k].is_integer():\n",
    "                        cfg[k] = int(cfg[k])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    cfg.buffer_size = cfg.demo_buffer_size\n",
    "    cfg.force_sparse = True\n",
    "    demo_id = 2\n",
    "    demo_eps = cfg.demo_n_eps\n",
    "\n",
    "    # Convenience\n",
    "    cfg.work_dir = '.'\n",
    "    cfg.task_title = cfg.task.replace(\"-\", \" \").title()\n",
    "    cfg.bin_size = (cfg.vmax - cfg.vmin) / (cfg.num_bins-1) # Bin size for discrete regression\n",
    "\n",
    "    # Model size\n",
    "    if cfg.get('model_size', None) is not None:\n",
    "        assert cfg.model_size in MODEL_SIZE.keys(), \\\n",
    "            f'Invalid model size {cfg.model_size}. Must be one of {list(MODEL_SIZE.keys())}'\n",
    "        for k, v in MODEL_SIZE[cfg.model_size].items():\n",
    "            cfg[k] = v\n",
    "        if cfg.task == 'mt30' and cfg.model_size == 19:\n",
    "            cfg.latent_dim = 512 # This checkpoint is slightly smaller\n",
    "\n",
    "    # Multi-task\n",
    "    cfg.multitask = cfg.task in TASK_SET.keys()\n",
    "    if cfg.multitask:\n",
    "        cfg.task_title = cfg.task.upper()\n",
    "        # Account for slight inconsistency in task_dim for the mt30 experiments\n",
    "        cfg.task_dim = 96 if cfg.task == 'mt80' or cfg.model_size in {1, 317} else 64\n",
    "    else:\n",
    "        cfg.task_dim = 0\n",
    "    cfg.tasks = TASK_SET.get(cfg.task, [cfg.task])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pusht force sparse reward:  True  display_cross:  False\n"
     ]
    }
   ],
   "source": [
    "from envs import make_env\n",
    "env = make_env(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pynput import mouse\n",
    "import time\n",
    "\n",
    "from tensordict.tensordict import TensorDict\n",
    "def to_td(obs, env, action=None, reward=None):\n",
    "    \"\"\"Creates a TensorDict for a new episode.\"\"\"\n",
    "    if isinstance(obs, dict):\n",
    "        obs = TensorDict(obs, batch_size=(), device='cpu')\n",
    "    else:\n",
    "        obs = obs.unsqueeze(0).cpu()\n",
    "    if action is None:\n",
    "        action = torch.full_like(env.rand_act(), float('nan'))\n",
    "    if reward is None:\n",
    "        reward = torch.tensor(float('nan'))\n",
    "    td = TensorDict(dict(\n",
    "        obs=obs,\n",
    "        action=action.unsqueeze(0),\n",
    "        reward=reward.unsqueeze(0),\n",
    "    ), batch_size=(1,))\n",
    "    return td\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = Buffer(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "ep 0 reward 1.0\n",
      "Buffer capacity: 20,000\n",
      "Storage required: 0.74 GB\n",
      "Using CUDA memory for storage.\n",
      "Success!\n",
      "ep 1 reward 1.0\n",
      "Success!\n",
      "ep 2 reward 1.0\n",
      "Success!\n",
      "ep 3 reward 1.0\n",
      "Success!\n",
      "ep 4 reward 1.0\n",
      "Success!\n",
      "ep 5 reward 1.0\n",
      "Success!\n",
      "ep 6 reward 1.0\n",
      "Success!\n",
      "ep 7 reward 1.0\n",
      "Success!\n",
      "ep 8 reward 1.0\n",
      "Success!\n",
      "ep 9 reward 1.0\n",
      "Success!\n",
      "ep 10 reward 1.0\n",
      "Success!\n",
      "ep 11 reward 1.0\n",
      "Success!\n",
      "ep 12 reward 1.0\n",
      "Success!\n",
      "ep 13 reward 1.0\n",
      "Success!\n",
      "ep 14 reward 1.0\n",
      "Success!\n",
      "ep 15 reward 1.0\n",
      "Success!\n",
      "ep 16 reward 1.0\n",
      "Success!\n",
      "ep 17 reward 1.0\n",
      "Success!\n",
      "ep 18 reward 1.0\n",
      "Success!\n",
      "ep 19 reward 1.0\n",
      "Success!\n",
      "ep 20 reward 1.0\n",
      "Success!\n",
      "ep 21 reward 1.0\n",
      "Success!\n",
      "ep 22 reward 1.0\n",
      "Success!\n",
      "ep 23 reward 1.0\n",
      "Success!\n",
      "ep 24 reward 1.0\n",
      "Success!\n",
      "ep 25 reward 1.0\n",
      "Success!\n",
      "ep 26 reward 1.0\n",
      "Success!\n",
      "ep 27 reward 1.0\n",
      "Success!\n",
      "ep 28 reward 1.0\n",
      "Success!\n",
      "ep 29 reward 1.0\n",
      "Success!\n",
      "ep 30 reward 1.0\n",
      "Success!\n",
      "ep 31 reward 1.0\n",
      "Success!\n",
      "ep 32 reward 1.0\n",
      "Success!\n",
      "ep 33 reward 1.0\n",
      "Success!\n",
      "ep 34 reward 1.0\n",
      "Success!\n",
      "ep 35 reward 1.0\n",
      "Success!\n",
      "ep 36 reward 1.0\n",
      "Success!\n",
      "ep 37 reward 1.0\n",
      "Success!\n",
      "ep 38 reward 1.0\n",
      "Success!\n",
      "ep 39 reward 1.0\n",
      "Success!\n",
      "ep 40 reward 1.0\n",
      "Success!\n",
      "ep 41 reward 1.0\n",
      "Success!\n",
      "ep 42 reward 1.0\n",
      "Success!\n",
      "ep 43 reward 1.0\n",
      "Success!\n",
      "ep 44 reward 1.0\n",
      "Success!\n",
      "ep 45 reward 1.0\n",
      "Success!\n",
      "ep 46 reward 1.0\n",
      "Success!\n",
      "ep 47 reward 1.0\n",
      "Success!\n",
      "ep 48 reward 1.0\n",
      "Success!\n",
      "ep 49 reward 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 57\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Step 3: Display using OpenCV\u001b[39;00m\n\u001b[1;32m     56\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m'\u001b[39m, reshaped)\n\u001b[0;32m---> 57\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m27\u001b[39m: \n\u001b[1;32m     59\u001b[0m     buffer\u001b[38;5;241m.\u001b[39madd(torch\u001b[38;5;241m.\u001b[39mcat(tds))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "global next_action\n",
    "next_action = np.array([0,0])\n",
    "\n",
    "minx, maxx = 500, 1500\n",
    "miny, maxy = 100, 1200\n",
    "def on_move(x, y):\n",
    "    if x < minx or x > maxx or y < miny or y > maxy: return np.array([0, 0])\n",
    "    \n",
    "    xnorm = (x - minx) / (maxx - minx)\n",
    "    ynorm = (y - miny) / (maxy - miny)\n",
    "\n",
    "    xnorm = max(0, min(1, xnorm))\n",
    "    ynorm = max(0, min(1, ynorm))\n",
    "\n",
    "    xnorm = 2 * xnorm - 1\n",
    "    ynorm = 2 * ynorm - 1\n",
    "\n",
    "    # print(f'Pointer moved to {(x, y)} -> {xnorm, ynorm}')\n",
    "    global next_action\n",
    "    next_action = np.array([xnorm, ynorm])\n",
    "\n",
    "# Create a listener\n",
    "listener = mouse.Listener(on_move=on_move)\n",
    "\n",
    "# Start the listener\n",
    "listener.start()\n",
    "cv2.destroyAllWindows()\n",
    "obs, done, ep_reward, t = env.reset(), False, 0, 0\n",
    "tds = [to_td(obs, env)]\n",
    "eps = 0; ts = 0; successes = 0; rewards = 0\n",
    "while eps < demo_eps:\n",
    "    # action = torch.Tensor(env.action_space.sample())\n",
    "    action = torch.Tensor(next_action)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    rewards += reward\n",
    "    # print(obs.shape, reward, action)\n",
    "    tds.append(to_td(obs, env, action, reward))\n",
    "\n",
    "    if done or ts >= 300:\n",
    "        print(f\"ep {eps} reward {rewards}\"); rewards = 0\n",
    "        successes += 1 if info['success'] else 0\n",
    "        eps += 1; ts = 0\n",
    "        buffer.add(torch.cat(tds))\n",
    "        obs, done, ep_reward, t = env.reset(), False, 0, 0\n",
    "        tds = [to_td(obs, env)]\n",
    "\n",
    "\n",
    "    img = obs.detach().cpu().numpy()\n",
    "    # Step 1: Reshape the stack into separate images\n",
    "    img = img.transpose(1, 2, 0)\n",
    "    # reshaped = np.hstack([img[:,:,i*3:(i*3)+3] for i in range(3)])\n",
    "    reshaped = img[:, :, -3:]\n",
    "    reshaped = cv2.resize(reshaped, (reshaped.shape[1] * 3, reshaped.shape[0] * 3), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Step 3: Display using OpenCV\n",
    "    cv2.imshow('row', reshaped)\n",
    "    k = cv2.waitKey(100) & 0xFF\n",
    "    if k == 27: \n",
    "        buffer.add(torch.cat(tds))\n",
    "        break\n",
    "\n",
    "    ts += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand 50 eps with 50 successes.\n"
     ]
    }
   ],
   "source": [
    "cv2.destroyAllWindows()\n",
    "listener.stop()\n",
    "print(f\"Rand {eps} eps with {successes} successes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffer saved to: /home/j/workspace/tdmpc2/demonstrations/HD_2_sparse\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5275"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "path = os.path.expanduser(f\"~/workspace/tdmpc2/demonstrations/HD_{demo_id}\" + \"_sparse\" if cfg.force_sparse else '')\n",
    "buffer.save(path)\n",
    "len(buffer._buffer.storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffer loaded from /home/j/workspace/tdmpc2/demonstrations//HD_0_sparse\n",
      "Loading from /home/j/workspace/tdmpc2/demonstrations//HD_0_sparse, transitions (3 frames): 8882\n",
      "Adding episode  tensor(1)  with r 1.0\n",
      "Buffer capacity: 20,000\n",
      "Storage required: 0.74 GB\n",
      "Using CUDA memory for storage.\n",
      "Adding episode  tensor(2)  with r 1.0\n",
      "Adding episode  tensor(3)  with r 1.0\n",
      "Adding episode  tensor(4)  with r 1.0\n",
      "Adding episode  tensor(5)  with r 1.0\n",
      "Adding episode  tensor(6)  with r 1.0\n",
      "Adding episode  tensor(7)  with r 1.0\n",
      "Adding episode  tensor(8)  with r 1.0\n",
      "Adding episode  tensor(9)  with r 1.0\n",
      "Adding episode  tensor(10)  with r 1.0\n",
      "Adding episode  tensor(11)  with r 1.0\n",
      "Adding episode  tensor(12)  with r 1.0\n",
      "Adding episode  tensor(13)  with r 1.0\n",
      "Adding episode  tensor(14)  with r 1.0\n",
      "Adding episode  tensor(15)  with r 1.0\n",
      "Adding episode  tensor(16)  with r 1.0\n",
      "Adding episode  tensor(17)  with r 1.0\n",
      "Adding episode  tensor(18)  with r 1.0\n",
      "Adding episode  tensor(19)  with r 1.0\n",
      "Adding episode  tensor(20)  with r 1.0\n",
      "Adding episode  tensor(21)  with r 1.0\n",
      "Adding episode  tensor(22)  with r 1.0\n",
      "Adding episode  tensor(23)  with r 1.0\n",
      "Adding episode  tensor(24)  with r 1.0\n",
      "Adding episode  tensor(25)  with r 1.0\n",
      "Adding episode  tensor(26)  with r 1.0\n",
      "Adding episode  tensor(27)  with r 1.0\n",
      "Adding episode  tensor(28)  with r 1.0\n",
      "Adding episode  tensor(29)  with r 1.0\n",
      "Adding episode  tensor(30)  with r 1.0\n",
      "Adding episode  tensor(31)  with r 1.0\n",
      "Adding episode  tensor(32)  with r 1.0\n",
      "Adding episode  tensor(33)  with r 1.0\n",
      "Adding episode  tensor(34)  with r 1.0\n",
      "Adding episode  tensor(35)  with r 1.0\n",
      "Adding episode  tensor(36)  with r 1.0\n",
      "Adding episode  tensor(37)  with r 1.0\n",
      "Adding episode  tensor(38)  with r 1.0\n",
      "Adding episode  tensor(39)  with r 1.0\n",
      "Adding episode  tensor(40)  with r 1.0\n",
      "Adding episode  tensor(41)  with r 1.0\n",
      "Adding episode  tensor(42)  with r 1.0\n",
      "Adding episode  tensor(43)  with r 1.0\n",
      "Adding episode  tensor(44)  with r 1.0\n",
      "Adding episode  tensor(45)  with r 1.0\n",
      "Adding episode  tensor(46)  with r 1.0\n",
      "Adding episode  tensor(47)  with r 1.0\n",
      "Adding episode  tensor(48)  with r 1.0\n",
      "Adding episode  tensor(49)  with r 1.0\n",
      "Adding episode  tensor(50)  with r 1.0\n",
      "Adding episode  tensor(51)  with r 1.0\n",
      "Adding episode  tensor(52)  with r 1.0\n",
      "Adding episode  tensor(53)  with r 1.0\n",
      "Adding episode  tensor(54)  with r 1.0\n",
      "Adding episode  tensor(55)  with r 1.0\n",
      "Adding episode  tensor(56)  with r 1.0\n",
      "Adding episode  tensor(57)  with r 1.0\n",
      "Adding episode  tensor(58)  with r 1.0\n",
      "Adding episode  tensor(59)  with r 1.0\n",
      "Adding episode  tensor(60)  with r 1.0\n",
      "Adding episode  tensor(61)  with r 1.0\n",
      "Adding episode  tensor(62)  with r 1.0\n",
      "Adding episode  tensor(63)  with r 1.0\n",
      "Adding episode  tensor(64)  with r 1.0\n",
      "Adding episode  tensor(65)  with r 1.0\n",
      "Adding episode  tensor(66)  with r 1.0\n",
      "Adding episode  tensor(67)  with r 1.0\n",
      "Adding episode  tensor(68)  with r 1.0\n",
      "Adding episode  tensor(69)  with r 1.0\n",
      "Adding episode  tensor(70)  with r 1.0\n",
      "Adding episode  tensor(71)  with r 1.0\n",
      "Adding episode  tensor(72)  with r 1.0\n",
      "Adding episode  tensor(73)  with r 1.0\n",
      "Adding episode  tensor(74)  with r 1.0\n",
      "Adding episode  tensor(75)  with r 1.0\n",
      "Adding episode  tensor(76)  with r 1.0\n",
      "Adding episode  tensor(77)  with r 1.0\n",
      "Adding episode  tensor(78)  with r 1.0\n",
      "Adding episode  tensor(79)  with r 1.0\n",
      "Adding episode  tensor(80)  with r 1.0\n",
      "Adding episode  tensor(81)  with r 1.0\n",
      "Adding episode  tensor(82)  with r 1.0\n",
      "Adding episode  tensor(83)  with r 1.0\n",
      "Adding episode  tensor(84)  with r 1.0\n",
      "Adding episode  tensor(85)  with r 1.0\n",
      "Adding episode  tensor(86)  with r 1.0\n",
      "Adding episode  tensor(87)  with r 1.0\n",
      "Adding episode  tensor(88)  with r 1.0\n",
      "Adding episode  tensor(89)  with r 1.0\n",
      "Adding episode  tensor(90)  with r 1.0\n",
      "Buffer loaded from /home/j/workspace/tdmpc2/demonstrations//HD_1_sparse\n",
      "Loading from /home/j/workspace/tdmpc2/demonstrations//HD_1_sparse, transitions (3 frames): 5752\n",
      "Adding episode  tensor(1)  with r 1.0\n",
      "Adding episode  tensor(2)  with r 1.0\n",
      "Adding episode  tensor(3)  with r 1.0\n",
      "Adding episode  tensor(4)  with r 1.0\n",
      "Adding episode  tensor(5)  with r 1.0\n",
      "Adding episode  tensor(6)  with r 1.0\n",
      "Adding episode  tensor(7)  with r 1.0\n",
      "Adding episode  tensor(8)  with r 1.0\n",
      "Adding episode  tensor(9)  with r 1.0\n",
      "Adding episode  tensor(10)  with r 1.0\n",
      "Adding episode  tensor(11)  with r 1.0\n",
      "Adding episode  tensor(12)  with r 1.0\n",
      "Adding episode  tensor(13)  with r 1.0\n",
      "Adding episode  tensor(14)  with r 1.0\n",
      "Adding episode  tensor(15)  with r 1.0\n",
      "Adding episode  tensor(16)  with r 1.0\n",
      "Adding episode  tensor(17)  with r 1.0\n",
      "Adding episode  tensor(18)  with r 1.0\n",
      "Adding episode  tensor(19)  with r 1.0\n",
      "Adding episode  tensor(20)  with r 1.0\n",
      "Adding episode  tensor(21)  with r 1.0\n",
      "Adding episode  tensor(22)  with r 1.0\n",
      "Adding episode  tensor(23)  with r 1.0\n",
      "Adding episode  tensor(24)  with r 1.0\n",
      "Adding episode  tensor(25)  with r 1.0\n",
      "Adding episode  tensor(26)  with r 1.0\n",
      "Adding episode  tensor(27)  with r 1.0\n",
      "Adding episode  tensor(28)  with r 1.0\n",
      "Adding episode  tensor(29)  with r 1.0\n",
      "Adding episode  tensor(30)  with r 1.0\n",
      "Adding episode  tensor(31)  with r 1.0\n",
      "Adding episode  tensor(32)  with r 1.0\n",
      "Adding episode  tensor(33)  with r 1.0\n",
      "Adding episode  tensor(34)  with r 1.0\n",
      "Adding episode  tensor(35)  with r 1.0\n",
      "Adding episode  tensor(36)  with r 1.0\n",
      "Adding episode  tensor(37)  with r 1.0\n",
      "Adding episode  tensor(38)  with r 1.0\n",
      "Adding episode  tensor(39)  with r 1.0\n",
      "Adding episode  tensor(40)  with r 1.0\n",
      "Adding episode  tensor(41)  with r 1.0\n",
      "Adding episode  tensor(42)  with r 1.0\n",
      "Adding episode  tensor(43)  with r 1.0\n",
      "Adding episode  tensor(44)  with r 1.0\n",
      "Adding episode  tensor(45)  with r 1.0\n",
      "Adding episode  tensor(46)  with r 1.0\n",
      "Adding episode  tensor(47)  with r 1.0\n",
      "Adding episode  tensor(48)  with r 1.0\n",
      "Adding episode  tensor(49)  with r 1.0\n",
      "Adding episode  tensor(50)  with r 1.0\n",
      "Buffer loaded from /home/j/workspace/tdmpc2/demonstrations//HD_2_sparse\n",
      "Loading from /home/j/workspace/tdmpc2/demonstrations//HD_2_sparse, transitions (3 frames): 5275\n",
      "Adding episode  tensor(1)  with r 1.0\n",
      "Adding episode  tensor(2)  with r 1.0\n",
      "Adding episode  tensor(3)  with r 1.0\n",
      "Adding episode  tensor(4)  with r 1.0\n",
      "Adding episode  tensor(5)  with r 1.0\n",
      "Adding episode  tensor(6)  with r 1.0\n",
      "Adding episode  tensor(7)  with r 1.0\n",
      "Adding episode  tensor(8)  with r 1.0\n",
      "Adding episode  tensor(9)  with r 1.0\n",
      "Adding episode  tensor(10)  with r 1.0\n",
      "Adding episode  tensor(11)  with r 1.0\n",
      "Adding episode  tensor(12)  with r 1.0\n",
      "Adding episode  tensor(13)  with r 1.0\n",
      "Adding episode  tensor(14)  with r 1.0\n",
      "Adding episode  tensor(15)  with r 1.0\n",
      "Adding episode  tensor(16)  with r 1.0\n",
      "Adding episode  tensor(17)  with r 1.0\n",
      "Adding episode  tensor(18)  with r 1.0\n",
      "Adding episode  tensor(19)  with r 1.0\n",
      "Adding episode  tensor(20)  with r 1.0\n",
      "Adding episode  tensor(21)  with r 1.0\n",
      "Adding episode  tensor(22)  with r 1.0\n",
      "Adding episode  tensor(23)  with r 1.0\n",
      "Adding episode  tensor(24)  with r 1.0\n",
      "Adding episode  tensor(25)  with r 1.0\n",
      "Adding episode  tensor(26)  with r 1.0\n",
      "Adding episode  tensor(27)  with r 1.0\n",
      "Adding episode  tensor(28)  with r 1.0\n",
      "Adding episode  tensor(29)  with r 1.0\n",
      "Adding episode  tensor(30)  with r 1.0\n",
      "Adding episode  tensor(31)  with r 1.0\n",
      "Adding episode  tensor(32)  with r 1.0\n",
      "Adding episode  tensor(33)  with r 1.0\n",
      "Adding episode  tensor(34)  with r 1.0\n",
      "Adding episode  tensor(35)  with r 1.0\n",
      "Adding episode  tensor(36)  with r 1.0\n",
      "Adding episode  tensor(37)  with r 1.0\n",
      "Adding episode  tensor(38)  with r 1.0\n",
      "Adding episode  tensor(39)  with r 1.0\n",
      "Adding episode  tensor(40)  with r 1.0\n",
      "Adding episode  tensor(41)  with r 1.0\n",
      "Adding episode  tensor(42)  with r 1.0\n",
      "Adding episode  tensor(43)  with r 1.0\n",
      "Adding episode  tensor(44)  with r 1.0\n",
      "Adding episode  tensor(45)  with r 1.0\n",
      "Adding episode  tensor(46)  with r 1.0\n",
      "Adding episode  tensor(47)  with r 1.0\n",
      "Adding episode  tensor(48)  with r 1.0\n",
      "Adding episode  tensor(49)  with r 1.0\n"
     ]
    }
   ],
   "source": [
    "from tensordict.tensordict import TensorDict\n",
    "def to_td(obs, action=None, reward=None):\n",
    "    \"\"\"Creates a TensorDict for a new episode.\"\"\"\n",
    "    if isinstance(obs, dict):\n",
    "        obs = TensorDict(obs, batch_size=(), device=device)\n",
    "    else:\n",
    "        obs = obs.unsqueeze(0).cpu()\n",
    "    if action is None or reward is None:\n",
    "        raise ValueError\n",
    "    td = TensorDict(dict(\n",
    "        obs=obs,\n",
    "        action=action.unsqueeze(0),\n",
    "        reward=reward.unsqueeze(0),\n",
    "    ), batch_size=(1,))\n",
    "    return td\n",
    "\n",
    "device = 'cpu'\n",
    "from torchrl.data.replay_buffers import LazyTensorStorage\t\n",
    "buf = Buffer(cfg)\n",
    "buf._buffer = buf._reserve_buffer(LazyTensorStorage(buf.capacity, device=torch.device(device)))\n",
    "names = [\"HD_0_sparse\", \"HD_1_sparse\", \"HD_2_sparse\"]\n",
    "base_path = os.path.expanduser(\"~/workspace/tdmpc2/demonstrations/\")\n",
    "for demo_name in names:\n",
    "    demo_path = base_path + \"/\" + demo_name\n",
    "    device = 'cuda' if 'cluster' in demo_path else 'cpu'\n",
    "    \n",
    "    load_buffer = Buffer(cfg) # HACK\n",
    "    load_buffer._capacity = cfg.demo_buffer_size\n",
    "    load_buffer._buffer = load_buffer._reserve_buffer(LazyTensorStorage(cfg.demo_buffer_size, device=torch.device(device)))\n",
    "    if not (load_buffer.load(os.path.expanduser(demo_path))):\n",
    "        raise FileNotFoundError(f\"Could not load buffer at {demo_path}\")\n",
    "\n",
    "    print(f\"Loading from {demo_path}, transitions (3 frames): {len(load_buffer._buffer.storage)}\")\n",
    "\n",
    "\n",
    "    # show the demos:\n",
    "    tds = []\n",
    "    n_ep = 0; r = torch.tensor(0.0, device=device)\n",
    "    for i in range(len(load_buffer._buffer.storage)):\n",
    "        obs, action, reward, episode = load_buffer._buffer[i][\"obs\"], load_buffer._buffer[i][\"action\"], load_buffer._buffer[i][\"reward\"], load_buffer._buffer[i][\"episode\"]\n",
    "        if 'cluster' not in demo_path: # dont show images on the cluster\n",
    "            toshow = obs.detach().cpu().numpy().transpose(1,2,0); title = str(demo_path.split('/')[-1])\n",
    "            cv2.imshow(title+'0', toshow[:, :, :3]); cv2.imshow(title+'1', toshow[:, :, 3:6]); cv2.imshow(title+'2', toshow[:, :, 6:])\n",
    "            cv2.waitKey(1)\n",
    "        if not tds or episode > n_ep:\n",
    "            if tds:\n",
    "                print(f\"Adding episode \", episode, f\" with r {r.detach().cpu()}\"); r = torch.tensor(0.0, device=device)\n",
    "                buf.add(torch.cat(tds))\n",
    "            tds = [to_td(obs, action, reward)]\n",
    "            n_ep = episode\n",
    "        else:\n",
    "            tds.append(to_td(obs, action, reward))\n",
    "        if not torch.isnan(reward): r += reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffer saved to: /home/j/workspace/tdmpc2/demonstrations/AGG_HD_0_1_2_sparse\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5275"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "agg_numbers = [entry.split('_')[1] for entry in names]\n",
    "\n",
    "import os\n",
    "path = os.path.expanduser(f\"~/workspace/tdmpc2/demonstrations/AGG_HD_{'_'.join(agg_numbers)}\" + \"_sparse\" if cfg.force_sparse else '')\n",
    "buffer.save(path)\n",
    "len(buffer._buffer.storage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
