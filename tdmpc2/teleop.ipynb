{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from hydra import initialize, initialize_config_dir, initialize_config_module, compose\n",
    "from omegaconf import OmegaConf\n",
    "from common.parser import parse_cfg\n",
    "from common import MODEL_SIZE, TASK_SET\n",
    "import re\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from common.buffer import Buffer, ReplayBuffer\n",
    "\n",
    "with initialize(version_base=None, config_path='.'):\n",
    "    cfg = compose(config_name='config.yaml')\n",
    "\n",
    "    # Logic\n",
    "    for k in cfg.keys():\n",
    "        try:\n",
    "            v = cfg[k]\n",
    "            if v == None:\n",
    "                v = True\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Algebraic expressions\n",
    "    for k in cfg.keys():\n",
    "        try:\n",
    "            v = cfg[k]\n",
    "            if isinstance(v, str):\n",
    "                match = re.match(r\"(\\d+)([+\\-*/])(\\d+)\", v)\n",
    "                if match:\n",
    "                    cfg[k] = eval(match.group(1) + match.group(2) + match.group(3))\n",
    "                    if isinstance(cfg[k], float) and cfg[k].is_integer():\n",
    "                        cfg[k] = int(cfg[k])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    cfg.buffer_size = cfg.demo_buffer_size\n",
    "    cfg.force_sparse = True\n",
    "    demo_id = 0\n",
    "    demo_eps = cfg.demo_n_eps\n",
    "\n",
    "    # Convenience\n",
    "    cfg.work_dir = '.'\n",
    "    cfg.task_title = cfg.task.replace(\"-\", \" \").title()\n",
    "    cfg.bin_size = (cfg.vmax - cfg.vmin) / (cfg.num_bins-1) # Bin size for discrete regression\n",
    "\n",
    "    # Model size\n",
    "    if cfg.get('model_size', None) is not None:\n",
    "        assert cfg.model_size in MODEL_SIZE.keys(), \\\n",
    "            f'Invalid model size {cfg.model_size}. Must be one of {list(MODEL_SIZE.keys())}'\n",
    "        for k, v in MODEL_SIZE[cfg.model_size].items():\n",
    "            cfg[k] = v\n",
    "        if cfg.task == 'mt30' and cfg.model_size == 19:\n",
    "            cfg.latent_dim = 512 # This checkpoint is slightly smaller\n",
    "\n",
    "    # Multi-task\n",
    "    cfg.multitask = cfg.task in TASK_SET.keys()\n",
    "    if cfg.multitask:\n",
    "        cfg.task_title = cfg.task.upper()\n",
    "        # Account for slight inconsistency in task_dim for the mt30 experiments\n",
    "        cfg.task_dim = 96 if cfg.task == 'mt80' or cfg.model_size in {1, 317} else 64\n",
    "    else:\n",
    "        cfg.task_dim = 0\n",
    "    cfg.tasks = TASK_SET.get(cfg.task, [cfg.task])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pusht force sparse reward:  True\n"
     ]
    }
   ],
   "source": [
    "from envs import make_env\n",
    "env = make_env(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pynput import mouse\n",
    "import time\n",
    "\n",
    "from tensordict.tensordict import TensorDict\n",
    "def to_td(obs, env, action=None, reward=None):\n",
    "    \"\"\"Creates a TensorDict for a new episode.\"\"\"\n",
    "    if isinstance(obs, dict):\n",
    "        obs = TensorDict(obs, batch_size=(), device='cpu')\n",
    "    else:\n",
    "        obs = obs.unsqueeze(0).cpu()\n",
    "    if action is None:\n",
    "        action = torch.full_like(env.rand_act(), float('nan'))\n",
    "    if reward is None:\n",
    "        reward = torch.tensor(float('nan'))\n",
    "    td = TensorDict(dict(\n",
    "        obs=obs,\n",
    "        action=action.unsqueeze(0),\n",
    "        reward=reward.unsqueeze(0),\n",
    "    ), batch_size=(1,))\n",
    "    return td\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "reward tensor(1.)\n",
      "Buffer capacity: 10,000\n",
      "Storage required: 0.37 GB\n",
      "Using CUDA memory for storage.\n",
      "Success!\n",
      "reward tensor(1.)\n",
      "Success!\n",
      "reward tensor(1.)\n",
      "Rand 3 eps with 3 successes.\n"
     ]
    }
   ],
   "source": [
    "buffer = Buffer(cfg)\n",
    "\n",
    "global next_action\n",
    "next_action = np.array([0,0])\n",
    "\n",
    "minx, maxx = 500, 1500\n",
    "miny, maxy = 100, 1200\n",
    "def on_move(x, y):\n",
    "    if x < minx or x > maxx or y < miny or y > maxy: return np.array([0, 0])\n",
    "    \n",
    "    xnorm = (x - minx) / (maxx - minx)\n",
    "    ynorm = (y - miny) / (maxy - miny)\n",
    "\n",
    "    xnorm = max(0, min(1, xnorm))\n",
    "    ynorm = max(0, min(1, ynorm))\n",
    "\n",
    "    xnorm = 2 * xnorm - 1\n",
    "    ynorm = 2 * ynorm - 1\n",
    "\n",
    "    # print(f'Pointer moved to {(x, y)} -> {xnorm, ynorm}')\n",
    "    global next_action\n",
    "    next_action = np.array([xnorm, ynorm])\n",
    "\n",
    "# Create a listener\n",
    "listener = mouse.Listener(on_move=on_move)\n",
    "\n",
    "# Start the listener\n",
    "listener.start()\n",
    "cv2.destroyAllWindows()\n",
    "obs, done, ep_reward, t = env.reset(), False, 0, 0\n",
    "tds = [to_td(obs, env)]\n",
    "eps = 0; ts = 0; successes = 0; rewards = 0\n",
    "while eps < demo_eps:\n",
    "    # action = torch.Tensor(env.action_space.sample())\n",
    "    action = torch.Tensor(next_action)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    rewards += reward\n",
    "    # print(obs.shape, reward, action)\n",
    "    tds.append(to_td(obs, env, action, reward))\n",
    "\n",
    "    if done or ts >= 300:\n",
    "        print(\"reward\", rewards); rewards = 0\n",
    "        successes += 1 if info['success'] else 0\n",
    "        eps += 1; ts = 0\n",
    "        buffer.add(torch.cat(tds))\n",
    "        obs, done, ep_reward, t = env.reset(), False, 0, 0\n",
    "        tds = [to_td(obs, env)]\n",
    "\n",
    "\n",
    "    img = obs.detach().cpu().numpy()\n",
    "    # Step 1: Reshape the stack into separate images\n",
    "    img = img.transpose(1, 2, 0)\n",
    "    # reshaped = np.hstack([img[:,:,i*3:(i*3)+3] for i in range(3)])\n",
    "    reshaped = img[:, :, -3:]\n",
    "    reshaped = cv2.resize(reshaped, (reshaped.shape[1] * 3, reshaped.shape[0] * 3), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Step 3: Display using OpenCV\n",
    "    cv2.imshow('row', reshaped)\n",
    "    k = cv2.waitKey(100) & 0xFF\n",
    "    if k == 27: \n",
    "        buffer.add(torch.cat(tds))\n",
    "        break\n",
    "\n",
    "    ts += 1\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "listener.stop()\n",
    "\n",
    "print(f\"Rand {eps} eps with {successes} successes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffer saved to: /home/j/workspace/tdmpc2/demonstrations/HD_1_sparse\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "281"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "path = os.path.expanduser(f\"~/workspace/tdmpc2/demonstrations/HD_{demo_id}\" + \"_sparse\" if cfg.force_sparse else '')\n",
    "buffer.save(path)\n",
    "len(buffer._buffer.storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffer loaded from /home/j/workspace/tdmpc2/demonstrations/HD_1_sparse\n",
      "Loading from /home/j/workspace/tdmpc2/demonstrations/HD_1_sparse, transitions (3 stacked frames): 281\n"
     ]
    }
   ],
   "source": [
    "from torchrl.data.replay_buffers import LazyTensorStorage\n",
    "\n",
    "buf = Buffer(cfg)\n",
    "load_buffer = Buffer(cfg) # HACK\n",
    "    \n",
    "buf._buffer = buf._reserve_buffer(LazyTensorStorage(buf.capacity, device=torch.device('cpu')))\n",
    "buf._num_eps += 1\n",
    "\n",
    "load_buffer._capacity = 10000\n",
    "load_buffer._buffer = load_buffer._reserve_buffer(LazyTensorStorage(10000, device=torch.device('cpu')))\n",
    "if not (load_buffer.load(os.path.expanduser(path))):\n",
    "    raise FileNotFoundError(f\"Could not load buffer at {cfg.demo_path}\")\n",
    "\n",
    "\n",
    "from tensordict.tensordict import TensorDict\n",
    "def to_td(obs, action=None, reward=None):\n",
    "    \"\"\"Creates a TensorDict for a new episode.\"\"\"\n",
    "    if isinstance(obs, dict):\n",
    "        obs = TensorDict(obs, batch_size=(), device='cpu')\n",
    "    else:\n",
    "        obs = obs.unsqueeze(0).cpu()\n",
    "    if action is None:\n",
    "        action = torch.full_like(env.rand_act(), float('nan'))\n",
    "    if reward is None:\n",
    "        reward = torch.tensor(float('nan'))\n",
    "    td = TensorDict(dict(\n",
    "        obs=obs,\n",
    "        action=action.unsqueeze(0),\n",
    "        reward=reward.unsqueeze(0),\n",
    "    ), batch_size=(1,))\n",
    "    return td\n",
    "\n",
    "# show the demos:\n",
    "for i in range(len(load_buffer._buffer.storage)):\n",
    "    obs, action, reward = load_buffer._buffer[i][\"obs\"], load_buffer._buffer[i][\"action\"], load_buffer._buffer[i][\"reward\"]\n",
    "    if 'cluster' not in path: # dont show images on the cluster\n",
    "        cv2.imshow(str(path.split('/')[-1]), obs.detach().cpu().numpy().transpose(1,2,0)[:, :, 6:])\n",
    "        cv2.waitKey(1)\n",
    "    buf.add(to_td(obs, action, reward))\n",
    "print(f\"Loading from {path}, transitions (3 stacked frames): {len(load_buffer._buffer.storage)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = img.reshape(64, 64, 3, 3)\n",
    "a = img\n",
    "cv2.imshow('a', a)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
